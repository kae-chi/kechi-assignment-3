{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL Problem 1\n",
    "\n",
    "In this EVAL assignment we will understand how seemingly insignificant changes in the input traffic distribution can lead to measurable differences in the behavior of queues and thus in the perceived service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "a) In the previous EVAL assignment, you discovered that the client sends requests to the server with inter-arrival times that are exponentially distributed with mean $1/\\lambda$ where $\\lambda$ is the arrival rate passed via the parameter `-a`. Also, the request lengths are exponentially distributed with mean $1/\\mu$ where $\\mu$ is the service rate passed via the parameter `-s`. Great! But as it turns out, that’s just the *default* behavior of the client. Let’s discover what else the client can do.  \n",
    "\n",
    "Which distribution the client uses is controller with an extra parameter `-d <dist. number>`, where `<dist. number>` is a number from 0 to 2. When passing `-d 0` you will be using the default exponential distribution. But what are the other two distributions? And does the `-d <dist.number>` parameter control both inter-arrival and service times?\n",
    "\n",
    "To begin answering these questions, run your server and client with the following parameters (let it run, it will take about 5 minutes):\n",
    "\n",
    "`./server_lim -q 1000 2222 & ./client -a 4.5 -s 5 -n 1500 -d 1 2222`\n",
    "\n",
    "Notice that the client is requested to generate traffic according to distribution 1. Just like you did in HW2, plot the experimental data of inter-arrival times and request lengths and recover the type and\n",
    "parameters of the distributions used by the client when `-d 1` is passed.\n",
    "\n",
    "Hint: *there is some guesswork involved in recovering the distribution parameters. Start by looking at the shape of the distribution produced by the collected data and make a guess about which distribution\n",
    "might be. Setting the mean will be easy if you think about it. If there is a standard deviation to set, explore integer fractions or multiples of the mean.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "b) Do the same as above to recover the parameters of distribution number 2. In a similar way as above, collect and post-process the server output data generated by the following parameter:\n",
    "\n",
    "`./server_lim -q 1000 2222 & ./client -a 4.5 -s 5 -n 1500 -d 2 2222`\n",
    "\n",
    "When decoding the distributions used by the client and their parameters, make conclusive statements about the distribution type for both inter-arrival times and service lengths, and explicitly state their\n",
    "mean and standard deviation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "c) We are now ready to see how different distributions affect the quality of service in our simple FIFO server. Let us focus on the comparison between an exponential distribution and whatever distribution 1 is. Run and collect experimental data for the following template command:\n",
    "\n",
    "`./server_lim -q 1000 2222 & ./client -a <arr. rate> -s 20 -n 1500 -d 0 2222`\n",
    "\n",
    "where `<arr. rate>` is varied from (and including) 10 up until 19. Notice that these experiments will ask the client to use an exponential distribution (`-d 0`). Use this set of experiments to produce a plot\n",
    "of the average response time as a function of the server utilization—in a way similar to what you did in HW1.\n",
    "\n",
    "Overlap on the same plot produced above the curve obtained by post-processing in the same exact way the results coming from running the following template command:\n",
    "\n",
    "`./server_lim -q 1000 2222 & ./client -a <arr. rate> -s 20 -n 1500 -d 1 2222`\n",
    "\n",
    "where once again `<arr. rate>` is varied from (and including) 10 up until 19. What can you conclude about the quality service perceived by the user when the load (a.k.a. its utilization) is comparable and\n",
    "only the distribution of the traffic characteristics changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "d)  Let us now explore what happens when the queue has a constrained size. To do that, run the following command:\n",
    "\n",
    "`./server_lim -q 10 2222 & ./client -a 19.6 -s 20 -n 1500 -d 0 2222`\n",
    "\n",
    "Post-process the server output to understand what happened to our requests. First, calculate the ratio of requests that get rejected over the total. Next, plot the distribution of the inter-rejection time,\n",
    "i.e. the time that elapses between a rejection and the next. What does that distribution look like? Do not recover the parameters of the distribution, but simply share your insights on the shape of the\n",
    "distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "e) Repeat the same analysis as above, when distribution number 1 is used instead, thus by running the following command:\n",
    "\n",
    "`./server_lim -q 10 2222 & ./client -a 19.6 -s 20 -n 1500 -d 1 2222`\n",
    "\n",
    "If you compare the new rejection rate and shape of the distribution, would you conclude that the new system (the one that uses `-d 1`) offers a better or worse service to its users?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment Here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
